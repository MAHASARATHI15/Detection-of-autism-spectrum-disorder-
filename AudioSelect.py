# -*- coding: utf-8 -*-

import warnings
warnings.filterwarnings('ignore')
"""somain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VGCfm16s9OC9qwup505I4_tMwhrBifRo
"""

from tkinter import Tk, filedialog
import librosa
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
import numpy as np
from keras.models import load_model
import serial
from serial import Serial

from pydub import AudioSegment
from pydub.playback import play









def initialize_serial(port):
    try:
        ser = Serial(
        port='COM10',
        baudrate=9600,
        parity='N',
        stopbits=serial.STOPBITS_ONE,  # Directly access constant
        bytesize=serial.EIGHTBITS,
        timeout=.1,
        rtscts=0
)
        print("Serial port initialized successfully.")
        return ser
    except Exception as e:
        print("Error initializing serial port:", e)
        return None





# Definir la ruta de la carpeta de sonidos
sounds_folder = 'sounds'

# Obtener la lista de archivos de audio y sus etiquetas
data = []
labels = []

# Definir los tipos de alarmas
alarm_types = ['ambulance', 'firetruck', 'traffic']

max_time_steps = 0

for alarm_type in alarm_types:
    folder_path = os.path.join(sounds_folder, alarm_type)
    for file in os.listdir(folder_path):
        if file.endswith('.wav'):
            file_path = os.path.join(folder_path, file)
            signal, sr = librosa.load(file_path, sr=None)
            spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr)
            data.append(spectrogram)
            labels.append(alarm_type)
            max_time_steps = max(max_time_steps, spectrogram.shape[1])

# Convertir las listas a matrices numpy
num_samples = len(data)
num_mel_bins = data[0].shape[0]

# Crear un arreglo numpy tridimensional para los datos
data_padded = np.zeros((num_samples, num_mel_bins, max_time_steps))

# Rellenar el arreglo con los espectrogramas y sus longitudes reales
for i in range(num_samples):
    data_padded[i, :, :data[i].shape[1]] = data[i]

# Convertir las etiquetas a un arreglo numpy
labels = np.array(labels)

print('Shape of the data after padding:', data_padded.shape)
print('Shape of the labels:', labels.shape)

# Encode the labels
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)


# Load the model
loaded_model = load_model("sound.h5")

import librosa
import numpy as np
from keras.models import load_model
from playsound import playsound
from IPython.display import Audio

def print_prediction(file_name, play_audio=True, display_audio=True):
    # Load the audio file
    signal, sr = librosa.load(file_name, sr=None)
    # Extract the spectrogram
    spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr)
    # Pad the spectrogram to match the input shape of the model
    padded_spectrogram = np.zeros((1, spectrogram.shape[0], data_padded.shape[2]))
    padded_spectrogram[0, :, :spectrogram.shape[1]] = spectrogram
    # Expand the dimensions to add the channel
    padded_spectrogram = np.expand_dims(padded_spectrogram, axis=-1)
    # Make predictions using the loaded model
    prediction = loaded_model.predict(padded_spectrogram)
    # Decode the predicted label
    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])
    #ser = initialize_serial('COM10') 
    #print("Predicted alarm type:", predicted_label[0])
    if predicted_label[0]=="traffic":
        print("Prediction: Traffic sound")
        ser.write(b'2')
        print(ser.write(b'2'))
    elif predicted_label[0]=="ambulance":
        print("Prediction: Ambulance sound")
        ser.write(b'1')
        print(ser.write(b'1'))
    elif predicted_label[0]=="firetruck":
        print("Prediction: Firetruck sound")
        ser.write(b'3')
        print(ser.write(b'3'))
    else:
        print("No audio file recorded. Exiting.")
    
    
        

    # Check if display_audio is True
 #   if display_audio:
  #      # Display the audio widget
   #     display(Audio(file_name))

    # Check if play_audio is True
  #  if play_audio:
        # Play the sound
   #\Desktop\Ambulance_Project\1\sound_202.wav'
#file_name = r'C:\Users\Admin\Desktop\Ambulance\sound_401.wav'








# Initialize Tkinter
root = Tk()
root.withdraw()  # Hide the main window

file_name = filedialog.askopenfilename(title="Select Audio", filetypes=[("Audio files", "*.wav")])

if file_name:
    print("Selected Audio:", file_name)
    # Perform operations with the selected audio file
    audio = AudioSegment.from_file(file_name)
    play(audio)

else:
    print("No audio file selected. Exiting.")
    sys.exit()


#C:\Users\Admin\Desktop\Desktop\Ambulance_Project\1
# Call the print_prediction function with play_audio set to False to suppress audio playback
print_prediction(file_name, play_audio=False)
