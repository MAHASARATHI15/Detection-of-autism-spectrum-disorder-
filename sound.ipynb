{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac72a85-aed4-415c-b7a7-4a6ca0553634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after padding: (422, 128, 2508)\n",
      "Shape of the labels: (422,)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Definir la ruta de la carpeta de sonidos\n",
    "sounds_folder = 'dataset'\n",
    "\n",
    "# Obtener la lista de archivos de audio y sus etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Definir los tipos de alarmas\n",
    "alarm_types = ['Autisim mild','Autisim moderate', 'normal']\n",
    "\n",
    "max_time_steps = 0\n",
    "\n",
    "for alarm_type in alarm_types:\n",
    "    folder_path = os.path.join(sounds_folder, alarm_type)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            signal, sr = librosa.load(file_path, sr=None)\n",
    "            spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "            data.append(spectrogram)\n",
    "            labels.append(alarm_type)\n",
    "            max_time_steps = max(max_time_steps, spectrogram.shape[1])\n",
    "\n",
    "# Convertir las listas a matrices numpy\n",
    "num_samples = len(data)\n",
    "num_mel_bins = data[0].shape[0]\n",
    "\n",
    "# Crear un arreglo numpy tridimensional para los datos\n",
    "data_padded = np.zeros((num_samples, num_mel_bins, max_time_steps))\n",
    "\n",
    "# Rellenar el arreglo con los espectrogramas y sus longitudes reales\n",
    "for i in range(num_samples):\n",
    "    data_padded[i, :, :data[i].shape[1]] = data[i]\n",
    "\n",
    "# Convertir las etiquetas a un arreglo numpy\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Shape of the data after padding:', data_padded.shape)\n",
    "print('Shape of the labels:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbf2dde-4a6f-458a-9ed3-673d94a6c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484c918f-f994-4e9f-bad6-57dd444bc1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 114s 12s/step - loss: 41.8005 - accuracy: 0.8810 - val_loss: 1.3606 - val_accuracy: 0.9706\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 76s 8s/step - loss: 11.1805 - accuracy: 0.9703 - val_loss: 1.4151 - val_accuracy: 0.9853\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.5561 - accuracy: 0.9851 - val_loss: 2.4687 - val_accuracy: 0.9853\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 64s 7s/step - loss: 2.7372 - accuracy: 0.9851 - val_loss: 3.2856 - val_accuracy: 0.9706\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 3.5195 - val_accuracy: 0.9706\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 62s 7s/step - loss: 1.5295 - accuracy: 0.9926 - val_loss: 3.5454 - val_accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 61s 7s/step - loss: 2.6947 - accuracy: 0.9963 - val_loss: 3.4281 - val_accuracy: 0.9706\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.8905 - accuracy: 0.9926 - val_loss: 3.1764 - val_accuracy: 0.9706\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 62s 7s/step - loss: 1.4631 - accuracy: 0.9926 - val_loss: 3.0579 - val_accuracy: 0.9706\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 63s 7s/step - loss: 0.7752 - accuracy: 0.9926 - val_loss: 2.8406 - val_accuracy: 0.9706\n",
      "3/3 [==============================] - 3s 872ms/step - loss: 22.8842 - accuracy: 0.9529\n",
      "Accuracy on test data: 0.9529411792755127\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_padded, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Expand the dimensions of the input data to add the channel\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # 3 alarm classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy on test data:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5d9769-d26e-4cd1-8720-39fd5188782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"Sound.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860a9f95-d335-4fd5-9fee-bc4db02f7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(\"sound.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241e3a2-6dc4-465c-abca-36eb4f67bdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837c9e31-6142-4954-87fe-43d3981a5585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7008\\1704664768.py:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(file_name, sr=None)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Admin\\\\Desktop\\\\Ambulance_Project\\\\1\\\\sound_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'C:\\\\Users\\\\Admin\\\\Desktop\\\\Ambulance_Project\\\\1\\\\sound_1.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAdmin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAmbulance_Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msound_1.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Call the print_prediction function with play_audio set to False to suppress audio playback\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m print_prediction(file_name, play_audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mprint_prediction\u001b[1;34m(file_name, play_audio, display_audio)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_prediction\u001b[39m(file_name, play_audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, display_audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     signal, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file_name, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Extract the spectrogram\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     spectrogram \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39msignal, sr\u001b[38;5;241m=\u001b[39msr)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Admin\\\\Desktop\\\\Ambulance_Project\\\\1\\\\sound_1.wav'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from playsound import playsound\n",
    "from IPython.display import Audio\n",
    "\n",
    "def print_prediction(file_name, play_audio=True, display_audio=True):\n",
    "    # Load the audio file\n",
    "    signal, sr = librosa.load(file_name, sr=None)\n",
    "    # Extract the spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "    # Pad the spectrogram to match the input shape of the model\n",
    "    padded_spectrogram = np.zeros((1, spectrogram.shape[0], data_padded.shape[2]))\n",
    "    padded_spectrogram[0, :, :spectrogram.shape[1]] = spectrogram\n",
    "    # Expand the dimensions to add the channel\n",
    "    padded_spectrogram = np.expand_dims(padded_spectrogram, axis=-1)\n",
    "    # Make predictions using the loaded model\n",
    "    prediction = loaded_model.predict(padded_spectrogram)\n",
    "    # Decode the predicted label\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "    print(\"Predicted alarm type:\", predicted_label[0])\n",
    "    \n",
    "    # Check if display_audio is True\n",
    "    if display_audio:\n",
    "        # Display the audio widget\n",
    "        display(Audio(file_name))\n",
    "    \n",
    "    # Check if play_audio is True\n",
    "    if play_audio:\n",
    "        # Play the sound\n",
    "        playsound(file_name)\n",
    "\n",
    "# Define the file name\n",
    "file_name = r'C:\\Users\\Admin\\Desktop\\Ambulance_Project\\1\\sound_1.wav'\n",
    "# Call the print_prediction function with play_audio set to False to suppress audio playback\n",
    "print_prediction(file_name, play_audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c9105e-763e-454d-925c-2faa5d65934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7046 sha256=66d5981dbe86502e1e8af708892894dcfadcc9e20d8443b32854bd20ccedfa9e\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\50\\98\\42\\62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d384207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
